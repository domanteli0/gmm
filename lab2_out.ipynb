{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881173d8",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [6]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ccafc5",
   "metadata": {
    "papermill": {
     "duration": 0.002585,
     "end_time": "2024-04-07T16:25:03.457944",
     "exception": false,
     "start_time": "2024-04-07T16:25:03.455359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lab2\n",
    "\n",
    "## Užduotis\n",
    "\n",
    "Antroje užduotyje reikia realizuoti vaizdų klasifikavimo modelį.\n",
    "Atsiskaitinėjant pratybų dėstytojas atsiųs testinių vaizdų, su kuriais turėsite pademonstruoti, kaip jūsų realizuotas modelis veikia.\n",
    "Atsiskaitymo metu, turėsite gebėti papasakoti, kaip realizuotas, jūsų modelis.\n",
    "Programinės įrangos sprendimą galite naudoti savo nuožiūra.\n",
    "\n",
    "- [ ] Klasės pasirenkamos savo nuožiūra, tačiau jų turi būti bent 3.\n",
    "- [ ] Duomenų rinkinys turi būti padalintas į mokymo ir testavimo aibes.\n",
    "- [ ] Su testavimo duomenų aibe reikia paskaičiuoti šias metrikas: klasifikavimo matrica (angl. *confusion matrix*), tikslumas, precizija, atkūrimas ir F1.\n",
    "\n",
    "Duomenų klasėms parinktos iš [OpenImages V6](https://storage.googleapis.com/openimages/web/index.html) objektų aptikimo uždavinio duomenų rinkinio.\n",
    "\n",
    "## Įgyvendintų papildomų funkcijų papildomi balai $P_2$ pasirinktinai:\n",
    "\n",
    "- [ ] Palyginimas palyginant aukšto lygio požymius (angl. _similiarity search_)\n",
    "- [ ] Sukuriant vartotojo sąsają ir modelio iškvietimą per REST API.\n",
    "\n",
    "### Duomenų atsiuntimas\n",
    "\n",
    "```{bash}\n",
    "brew install awscli\n",
    "```\n",
    "\n",
    "```{bash}\n",
    "pipx install oidv6\n",
    "```\n",
    "```{bash}\n",
    "oidv6 downloader --classes Airplane Bus Boat Train --type_data train --no-labels --limit 500 --dest_dir lab2/OIDv6/train\n",
    "```\n",
    "```{bash}\n",
    "oidv6 downloader --classes Airplane Bus Boat Train --type_data test --no-labels --limit 100 --dest_dir lab2/OIDv6/test\n",
    "```\n",
    "```{bash}\n",
    "oidv6 downloader --classes Airplane Bus Boat Train --type_data validation --no-labels --limit 100 --dest_dir lab2/OIDv6/validation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4710795b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T16:25:03.464141Z",
     "iopub.status.busy": "2024-04-07T16:25:03.463908Z",
     "iopub.status.idle": "2024-04-07T16:25:05.067411Z",
     "shell.execute_reply": "2024-04-07T16:25:05.067117Z"
    },
    "papermill": {
     "duration": 1.608202,
     "end_time": "2024-04-07T16:25:05.068410",
     "exception": false,
     "start_time": "2024-04-07T16:25:03.460208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from importlib import reload\n",
    "from copy import deepcopy\n",
    "from torchvision.transforms import transforms as trans\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e84473b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T16:25:05.071234Z",
     "iopub.status.busy": "2024-04-07T16:25:05.071090Z",
     "iopub.status.idle": "2024-04-07T16:25:05.094187Z",
     "shell.execute_reply": "2024-04-07T16:25:05.093946Z"
    },
    "papermill": {
     "duration": 0.025324,
     "end_time": "2024-04-07T16:25:05.094974",
     "exception": false,
     "start_time": "2024-04-07T16:25:05.069650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Device\n",
    "import torch\n",
    "\n",
    "device: torch.device = torch.device('cpu')\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"WARN: Neither MPS nor CUDA device was found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b48cf26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T16:25:05.097425Z",
     "iopub.status.busy": "2024-04-07T16:25:05.097321Z",
     "iopub.status.idle": "2024-04-07T16:25:05.101524Z",
     "shell.execute_reply": "2024-04-07T16:25:05.101302Z"
    },
    "papermill": {
     "duration": 0.006255,
     "end_time": "2024-04-07T16:25:05.102290",
     "exception": false,
     "start_time": "2024-04-07T16:25:05.096035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIM = 32\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "class Net(nn.Module):\n",
    "\tdef __init__(self, num_classes=3):\n",
    "\t\tsuper(Net, self).__init__()\n",
    "\t\tself.softmax = nn.Softmax()\n",
    "\n",
    "\t\tself.conv1 = nn.Conv2d(in_channels=NUM_CHANNELS, out_channels=32, kernel_size=3, padding=1)\n",
    "\t\tself.batchnorm1 = nn.BatchNorm2d(32)\n",
    "\t\tself.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "\t\tself.batchnorm2 = nn.BatchNorm2d(32)\n",
    "\t\tself.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\t\tself.dropout1 = nn.Dropout2d(p=0.2)\n",
    "\n",
    "\t\tself.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\t\tself.batchnorm3 = nn.BatchNorm2d(64)\n",
    "\t\tself.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\t\tself.batchnorm4 = nn.BatchNorm2d(64)\n",
    "\t\tself.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\t\tself.dropout2 = nn.Dropout2d(p=0.3)\n",
    "\n",
    "\t\tself.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "\t\tself.batchnorm5 = nn.BatchNorm2d(128)\n",
    "\t\tself.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\t\tself.batchnorm6 = nn.BatchNorm2d(128)\n",
    "\t\tself.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\t\tself.dropout3 = nn.Dropout2d(p=0.4)\n",
    "\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.fc1 = nn.Linear(128 * (DIM // 8) * (DIM // 8), 128)\n",
    "\t\tself.batchnorm_fc = nn.BatchNorm1d(128)\n",
    "\t\tself.dropout_fc = nn.Dropout(p=0.5)\n",
    "\t\tself.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = torch.relu(self.conv1(x))\n",
    "\t\tx = self.batchnorm1(x)\n",
    "\t\tx = torch.relu(self.conv2(x))\n",
    "\t\tx = self.batchnorm2(x)\n",
    "\t\tx = self.maxpool1(x)\n",
    "\t\tx = self.dropout1(x)\n",
    "\n",
    "\t\tx = torch.relu(self.conv3(x))\n",
    "\t\tx = self.batchnorm3(x)\n",
    "\t\tx = torch.relu(self.conv4(x))\n",
    "\t\tx = self.batchnorm4(x)\n",
    "\t\tx = self.maxpool2(x)\n",
    "\t\tx = self.dropout2(x)\n",
    "\n",
    "\t\tx = torch.relu(self.conv5(x))\n",
    "\t\tx = self.batchnorm5(x)\n",
    "\t\tx = torch.relu(self.conv6(x))\n",
    "\t\tx = self.batchnorm6(x)\n",
    "\t\tx = self.maxpool3(x)\n",
    "\t\tx = self.dropout3(x)\n",
    "\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = torch.relu(self.fc1(x))\n",
    "\t\tx = self.batchnorm_fc(x)\n",
    "\t\tx = self.dropout_fc(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac603cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T16:25:05.104640Z",
     "iopub.status.busy": "2024-04-07T16:25:05.104546Z",
     "iopub.status.idle": "2024-04-07T16:25:05.136894Z",
     "shell.execute_reply": "2024-04-07T16:25:05.136334Z"
    },
    "papermill": {
     "duration": 0.034554,
     "end_time": "2024-04-07T16:25:05.137854",
     "exception": false,
     "start_time": "2024-04-07T16:25:05.103300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net(num_classes = NUM_CLASSES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739b03d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T16:25:05.142546Z",
     "iopub.status.busy": "2024-04-07T16:25:05.142414Z",
     "iopub.status.idle": "2024-04-07T16:25:05.145690Z",
     "shell.execute_reply": "2024-04-07T16:25:05.145468Z"
    },
    "papermill": {
     "duration": 0.00578,
     "end_time": "2024-04-07T16:25:05.146385",
     "exception": false,
     "start_time": "2024-04-07T16:25:05.140605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_trans = trans.Compose([\n",
    "  trans.RandomHorizontalFlip(),\n",
    "  trans.RandomRotation(20),\n",
    "  trans.ColorJitter(brightness = 0.4, contrast = 0.2, saturation = 0.2, hue=0.1),\n",
    "  trans.RandomGrayscale(p=0.1),\n",
    "  trans.RandomResizedCrop(size = (32, 32), scale = (0.75, 0.75)),\n",
    "  trans.ToTensor(),\n",
    "  trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "validation_trans = trans.Compose([\n",
    "  trans.Resize((32, 32)),\n",
    "  trans.ToTensor(),\n",
    "  trans.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_trans = validation_trans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d367bd",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11aec6ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T16:25:05.148895Z",
     "iopub.status.busy": "2024-04-07T16:25:05.148795Z",
     "iopub.status.idle": "2024-04-07T16:25:05.244662Z",
     "shell.execute_reply": "2024-04-07T16:25:05.244213Z"
    },
    "papermill": {
     "duration": 0.097874,
     "end_time": "2024-04-07T16:25:05.245321",
     "exception": true,
     "start_time": "2024-04-07T16:25:05.147447",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lab2/OIDv6/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds      \u001b[38;5;241m=\u001b[39m \u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlab2/OIDv6/train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_trans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m validation_ds \u001b[38;5;241m=\u001b[39m ImageFolder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlab2/OIDv6/validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform \u001b[38;5;241m=\u001b[39m validation_trans)\n\u001b[1;32m      3\u001b[0m test_ds       \u001b[38;5;241m=\u001b[39m ImageFolder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlab2/OIDv6/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,       transform \u001b[38;5;241m=\u001b[39m test_trans)\n",
      "File \u001b[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lab2/OIDv6/train'"
     ]
    }
   ],
   "source": [
    "train_ds      = ImageFolder(\"lab2/OIDv6/train\",      transform = train_trans)\n",
    "validation_ds = ImageFolder(\"lab2/OIDv6/validation\", transform = validation_trans)\n",
    "test_ds       = ImageFolder(\"lab2/OIDv6/test\",       transform = test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2371c3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_dl      = DataLoader(train_ds,      shuffle = True,  batch_size = BATCH_SIZE, num_workers = 8)\n",
    "validation_dl = DataLoader(validation_ds, shuffle = False, batch_size = BATCH_SIZE, num_workers = 8)\n",
    "test_dl       = DataLoader(test_ds,       shuffle = False, batch_size = BATCH_SIZE, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee5291",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888e9c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a624e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import cat as c\n",
    "from torch import tensor as t\n",
    "\n",
    "import lab2.graphs\n",
    "reload(lab2.graphs)\n",
    "from lab2.graphs import display_loss, display_acc\n",
    "\n",
    "train_history = {\n",
    "  'ls': torch.zeros(0),\n",
    "  'ys': torch.zeros(0, 0),\n",
    "  'y_hats': torch.zeros(0, 0)\n",
    "}; th = train_history\n",
    "\n",
    "validation_history = {\n",
    "  'ls': torch.zeros(0),\n",
    "  'ys': torch.zeros(0, 0),\n",
    "  'y_hats': torch.zeros(0, 0)\n",
    "}; vh = validation_history\n",
    "\n",
    "# NUM_EPOCHS = 30\n",
    "NUM_EPOCHS = 5\n",
    "VALIDATE = True\n",
    "\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  model.train()\n",
    "\n",
    "  l = t([])\n",
    "  y = t([])\n",
    "  y_hat = t([])\n",
    "  ix = -1\n",
    "  for inputs, labels in train_dl:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y =     c((y, labels.detach().cpu().to(\"cpu\")), dim = -1)\n",
    "    y_hat = c((y_hat, softmax(outputs).argmax(dim = -1).detach().cpu().to(\"cpu\")), dim = -1)\n",
    "    l = c((l, loss.cpu().detach().to(\"cpu\").reshape(1)))\n",
    "\n",
    "    if ix == 0:\n",
    "      break\n",
    "    ix -= 1\n",
    "\n",
    "  print(f\"  l_shape {l.shape}\")\n",
    "  print(f\"  y_shape {y.shape}\")\n",
    "  print(f\"  ys_shape {th['ys'].shape}\")\n",
    "  \n",
    "  th['ls'] = c((th['ls'], torch.mean(l).unsqueeze(0)))\n",
    "  th['ys'] = c((th['ys'].reshape(-1, y.shape[0]), y.unsqueeze(0)))\n",
    "  th['y_hats'] = c((th['y_hats'].reshape(-1, y.shape[0]), y_hat.unsqueeze(0)))\n",
    "\n",
    "  if VALIDATE:\n",
    "    l = t([])\n",
    "    y = t([])\n",
    "    y_hat = t([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in validation_dl:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        y =     c((y, labels.detach().cpu().to(\"cpu\")), dim = -1)\n",
    "        y_hat = c((y_hat, softmax(outputs).argmax(dim = -1).detach().cpu().to(\"cpu\")), dim = -1)\n",
    "        l = c((l, loss.cpu().detach().to(\"cpu\").reshape(1)))\n",
    "  \n",
    "    vh['ls']     = c((vh['ls'], torch.mean(l).unsqueeze(0)))\n",
    "    vh['ys']     = c((vh['ys'].reshape(-1, y.shape[0]), y.unsqueeze(0)))\n",
    "    vh['y_hats'] = c((vh['y_hats'].reshape(-1, y.shape[0]), y_hat.unsqueeze(0)))\n",
    "\n",
    "  plt.close()\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (8, 3))\n",
    "  display_loss(ax1, train_history, label = 'Train loss')\n",
    "  display_acc(ax2, train_history, label = 'Train acc')\n",
    "\n",
    "  if VALIDATE:\n",
    "    display_loss(ax1, validation_history, label = 'Validation loss')\n",
    "    display_acc(ax2, validation_history, label = 'Validation acc')\n",
    "\n",
    "  plt.pause(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc1631",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_history = {\n",
    "  'ls': torch.zeros(0),\n",
    "  'ys': torch.zeros(0, 0),\n",
    "  'y_hats': torch.zeros(0,0)\n",
    "}; test_history\n",
    "\n",
    "\n",
    "y = t([])\n",
    "y_hat = t([])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for inputs, labels in test_dl:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    y =     c((y, labels.detach().cpu().to(\"cpu\")), dim = -1)\n",
    "    y_hat = c((y_hat, softmax(outputs).argmax(dim = -1).detach().cpu().to(\"cpu\")), dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abd34d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_hat)\n",
    "class_names = test_ds.classes\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Ground truth')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y, y_hat, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.20259,
   "end_time": "2024-04-07T16:25:05.767267",
   "environment_variables": {},
   "exception": true,
   "input_path": "lab2.ipynb",
   "output_path": "lab2_out.ipynb",
   "parameters": {},
   "start_time": "2024-04-07T16:25:02.564677",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}