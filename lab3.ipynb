{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T00:54:10.203675Z",
     "start_time": "2024-05-08T00:54:04.675133Z"
    }
   },
   "source": [
    "import pathlib\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lab3\n",
    "reload(lab3)\n",
    "\n",
    "import lab3.classes\n",
    "reload(lab3.classes)\n",
    "import lab3.classes as cs\n",
    "\n",
    "import lab3.show\n",
    "reload(lab3.show)\n",
    "from lab3.show import display_img_with_masks, display_masks\n",
    "\n",
    "import lab3.trans\n",
    "reload(lab3.trans)\n",
    "from lab3.trans import validation_trans, train_trans, test_trans\n",
    "\n",
    "import lab3.dataset\n",
    "reload(lab3.dataset)\n",
    "from lab3.dataset import FiftyOneDataset\n",
    "\n",
    "import lab3.net\n",
    "reload(lab3.net)\n",
    "from lab3.net import Net\n",
    "\n",
    "import lab1.device\n",
    "reload(lab1.device)\n",
    "from lab1.device import device\n",
    "\n",
    "import lab3.util\n",
    "reload(lab3.util)\n",
    "from lab3.util import seconds_to_time\n",
    "\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T00:54:18.226370Z",
     "start_time": "2024-05-08T00:54:10.204743Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "import fiftyone as fo\n",
    "import fiftyone.utils.openimages as fouo\n",
    "import fiftyone.zoo as foz\n",
    "import cv2\n",
    "\n",
    "def download(split = \"train\", max_samples: int = 2000):\n",
    "  return foz.load_zoo_dataset(\n",
    "    \"open-images-v6\",\n",
    "    split        = split,\n",
    "    label_types  = [\"segmentations\", \"detections\"],\n",
    "    classes      = cs.classes_no_background,\n",
    "    max_samples  = max_samples,\n",
    "    dataset_dir  = \"data-lab3\",\n",
    "    dataset_name =f\"open-images-v6-{split}\"\n",
    "  )\n",
    "\n",
    "def load(split = \"train\"):\n",
    "  dataset =  fouo.OpenImagesV6DatasetImporter(\n",
    "    dataset_dir = f\"data-lab3/{split}\",\n",
    "    label_types = \"segmentations\"\n",
    "  )\n",
    "\n",
    "  dataset.setup()\n",
    "\n",
    "  return dataset\n",
    "\n",
    "def resize_dataset(path):\n",
    "  for p in os.listdir(path):\n",
    "    image = cv2.imread(path + p, cv2.IMREAD_UNCHANGED)\n",
    "    print(image)\n",
    "    \n",
    "    if image.shape[1] > image.shape[0]:\n",
    "      scale = 128 / image.shape[0]\n",
    "    else:\n",
    "      scale = 128 / image.shape[1]\n",
    "    \n",
    "    width = int(image.shape[1] * scale)\n",
    "    height = int(image.shape[0] * scale)\n",
    "    dim = (width, height)\n",
    "    \n",
    "    # resize image\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    print('Resized Dimensions : ',resized.shape)\n",
    "\n",
    "RESIZE = False\n",
    "if RESIZE:\n",
    "  resize_dataset('./data-lab3/test/data/')\n",
    "  resize_dataset('./data-lab3/validation/data/')\n",
    "  resize_dataset('./data-lab3/train/data/')\n",
    "# train_ds = download(\"train\")\n",
    "# valid_ds = download(\"validation\", max_samples = 300)\n",
    "# test_ds  = download(\"test\", max_samples = 300)\n",
    "\n",
    "train_ds = load(\"train\")\n",
    "valid_ds = load(\"validation\")\n",
    "\n",
    "train_ds #, fo.list_datasets()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fiftyone.utils.openimages.OpenImagesV6DatasetImporter at 0x16819a420>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T00:55:18.080986Z",
     "start_time": "2024-05-08T00:54:18.227060Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.utils.data as tud\n",
    "\n",
    "train_dataset = FiftyOneDataset(train_ds, train_trans)\n",
    "valid_dataset = FiftyOneDataset(valid_ds, validation_trans)\n",
    "\n",
    "num_workers = 8\n",
    "batch_size = 128\n",
    "\n",
    "train_ld = tud.DataLoader(train_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = True)\n",
    "valid_ld = tud.DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = False)\n",
    "\n",
    "print(f'Train: {len(train_dataset)}, Test: {len(valid_dataset)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 808, Test: 157\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T00:55:18.091374Z",
     "start_time": "2024-05-08T00:55:18.081592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from statistics import mean\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import tensor as t, concat as c\n",
    "\n",
    "ZERO = torch.zeros(0, 6, 128, 128) < 1\n",
    "\n",
    "class Stats:\n",
    "  length = 0\n",
    "  \n",
    "  dice: float = 0\n",
    "  iou:  float  = 0\n",
    "  f1_micro: float = 0\n",
    "  f1_macro: float = 0\n",
    "  \n",
    "  loss_acum: list[float] = []\n",
    "  \n",
    "  def init(self):\n",
    "    pass\n",
    "  \n",
    "  def add_data(self, ys: torch.Tensor, y_hats: torch.Tensor, loss: float):\n",
    "    # print(f\"TYPE: {type(ys)}\")\n",
    "    # print(f\"LEN:  {ys}\")\n",
    "    self.length += ys.shape[0]\n",
    "    self.loss_acum.append(loss)\n",
    "\n",
    "    intersection = torch.bitwise_and(ys, y_hats)\n",
    "    union = torch.bitwise_or(ys, y_hats)\n",
    "\n",
    "    intersection = torch.sum(intersection)\n",
    "    union = torch.sum(union)\n",
    "\n",
    "    # Jaccard = || A \\intersect B || / || A \\union B ||\n",
    "    iou = intersection / union\n",
    "\n",
    "    # DICE = 2 || A \\intersect B || / (||A|| + ||B||)\n",
    "    dice = 2 * intersection / (torch.sum(ys) + torch.sum(y_hats))\n",
    "\n",
    "    # Flatten the tensors\n",
    "    ys_flat = ys.view(-1).numpy()\n",
    "    y_hats_flat = y_hats.view(-1).numpy()\n",
    "\n",
    "    # Calculate Micro-F1 and Macro-F1 scores\n",
    "    micro_f1 = f1_score(ys_flat, y_hats_flat, average='micro')\n",
    "    macro_f1 = f1_score(ys_flat, y_hats_flat, average='macro')\n",
    "    \n",
    "    self.iou  += iou.item()\n",
    "    self.dice += dice.item()\n",
    "    self.f1_macro += macro_f1.item()\n",
    "    self.f1_micro += micro_f1.item()\n",
    "  \n",
    "  def get_stats(self):\n",
    "    return (\n",
    "      self.iou / self.length, \n",
    "      self.dice / self.length,\n",
    "      self.f1_micro / self.length,\n",
    "      self.f1_macro / self.length,\n",
    "      mean(self.loss_acum)\n",
    "    )\n",
    "\n",
    "def run_epoch(model: Net,\n",
    "              loader: torch.utils.data.DataLoader,\n",
    "              loss_fn, optimizer):\n",
    "  stats = Stats()\n",
    "  IS_TRAIN = optimizer is not None\n",
    "  \n",
    "  if IS_TRAIN:\n",
    "    model.train()\n",
    "  else:\n",
    "    model.eval()\n",
    "\n",
    "  ix = -1\n",
    "  for images, true_masks in loader:\n",
    "    images = images.to(device)\n",
    "    true_masks = true_masks.to(device)\n",
    "    \n",
    "    if not IS_TRAIN:\n",
    "      with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "    else:\n",
    "      predictions = model(images)\n",
    "      \n",
    "\n",
    "    loss = loss_fn(true_masks, predictions)\n",
    "\n",
    "    # print(f\"  PRED_MAX: {predictions.max()}\")\n",
    "    predictions = predictions > 0.5\n",
    "    true_masks = true_masks > 0.5\n",
    "    stats.add_data(true_masks.cpu().detach(), predictions.cpu().detach(), loss.cpu().detach().item())\n",
    "    \n",
    "    if IS_TRAIN:\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "    if ix == 0:\n",
    "      break\n",
    "    ix -= 1\n",
    "  \n",
    "  ret = stats.get_stats()\n",
    "  return ret\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T00:55:18.096747Z",
     "start_time": "2024-05-08T00:55:18.092985Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_and_eval(model, train_ld, valid_ld, epoch_count = 10, learning_rate = 1e-3):\n",
    "  loss_func = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "  start_time = datetime.now()\n",
    "\n",
    "  train_loss_acum  = []\n",
    "  train_iou_acum   = []\n",
    "  train_dice_acum  = []\n",
    "  train_micro_acum = []\n",
    "  train_macro_acum = []\n",
    "  valid_loss_acum  = []\n",
    "  valid_iou_acum   = []\n",
    "  valid_dice_acum  = []\n",
    "  valid_micro_acum = []\n",
    "  valid_macro_acum = []\n",
    "  \n",
    "  for epoch in range(epoch_count):\n",
    "    print(f'EPOCH: {epoch + 1} / {epoch_count}')\n",
    "    train_iou, train_dice, train_micro, train_macro, train_loss = run_epoch(model, train_ld, loss_func, optimizer)\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    elapsed = seconds_to_time((current_time - start_time).total_seconds())\n",
    "    print(f'  train      | Elapsed: {elapsed}')\n",
    "\n",
    "    valid_iou, valid_dice, valid_micro, valid_macro, valid_loss = run_epoch(model, valid_ld, loss_func, optimizer)\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    elapsed = seconds_to_time((current_time - start_time).total_seconds())\n",
    "    print(f'  valid      | Elapsed: {elapsed}')\n",
    "\n",
    "    train_iou_acum.append(train_iou)\n",
    "    train_dice_acum.append(train_dice)\n",
    "    train_micro_acum.append(train_micro)\n",
    "    train_macro_acum.append(train_macro)\n",
    "    train_loss_acum.append(train_loss)\n",
    "    \n",
    "    valid_iou_acum.append(valid_iou)\n",
    "    valid_dice_acum.append(valid_dice)\n",
    "    valid_micro_acum.append(valid_micro)\n",
    "    valid_macro_acum.append(valid_macro)\n",
    "    valid_loss_acum.append(valid_loss)\n",
    "\n",
    "    print(f'  Training Loss:  {train_loss},  Validation Loss:  {valid_loss}')\n",
    "    print(f'  Training IoU:   {train_iou},   Validation IoU:   {valid_iou}')\n",
    "    print(f'  Training Dice:  {train_dice},  Validation Dice:  {valid_dice}')\n",
    "    print(f'  Training Micro: {train_micro}, Validation Micro: {valid_micro}')\n",
    "    print(f'  Training Macro: {train_macro}, Validation Macro: {valid_macro}')\n",
    "\n",
    "  return train_iou_acum, valid_iou_acum, train_dice_acum, valid_dice_acum, train_micro_acum, valid_micro_acum, train_macro_acum, valid_macro_acum, train_loss_acum, valid_loss_acum"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T00:55:18.099562Z",
     "start_time": "2024-05-08T00:55:18.097412Z"
    }
   },
   "source": [
    "def plot(train, valid, label = \"IoU\"):\n",
    "  plt.clf()\n",
    "  plt.plot(train, 'b', label = f'Training {label}')\n",
    "  plt.plot(valid, 'r', label = f'Validation {label}')\n",
    "  plt.ylim(0.0, 1.0)\n",
    "  plt.legend()\n",
    "  plt.show()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T00:55:18.101550Z",
     "start_time": "2024-05-08T00:55:18.100203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_dataset[0]\n",
    "# np.zeros(4).reshape((2, 2)).shape"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-08T00:55:18.102194Z"
    }
   },
   "source": [
    "model = Net(train_dataset[0][0].shape[0], num_classes = cs.num_classes).to(device)\n",
    "print(f'Parameter count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "train_iou, valid_iou, train_dice, valid_dice, train_micro, valid_micro, train_macro, valid_macro, train_loss, valid_loss = train_and_eval(model, train_ld, valid_ld, epoch_count = EPOCHS, learning_rate = 1e-3)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count: 1,928,582\n",
      "EPOCH: 1 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_deprecated.py:12: UserWarning: The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
      "  warnings.warn(\n",
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_deprecated.py:12: UserWarning: The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
      "  warnings.warn(\n",
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_deprecated.py:12: UserWarning: The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
      "  warnings.warn(\n",
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_deprecated.py:12: UserWarning: The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
      "  warnings.warn(\n",
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_deprecated.py:12: UserWarning: The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
      "  warnings.warn(\n",
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_deprecated.py:12: UserWarning: The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
      "  warnings.warn(\n",
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_deprecated.py:12: UserWarning: The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
      "  warnings.warn(\n",
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_deprecated.py:12: UserWarning: The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
      "  warnings.warn(\n",
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PRED_MAX: 0.9480430483818054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PRED_MAX: 0.8741291165351868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PRED_MAX: 0.925017774105072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PRED_MAX: 0.9125930070877075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "iter = train_ld.__iter__()\n",
    "img: torch.Tensor; mask: torch.Tensor; prediction: torch.Tensor\n",
    "imgs, masks = next(iter)\n",
    "\n",
    "# prediction = model(img.unsqueeze(0).to(device)).cpu().detach().squeeze(0) img.shape, mask.unique(), mask.max()\n",
    "# for i in range(10):\n",
    "#   print(masks[0].max())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "plot(train_iou, valid_iou)\n",
    "plot(train_dice, valid_dice, label = \"dice\")\n",
    "plot(train_micro, valid_micro, label = \"micro\")\n",
    "plot(train_macro, valid_macro, label = \"macro\")\n",
    "plot(train_loss, valid_loss, label = \"loss\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "torch.save(model, 'lab3/net_attempt2.pth')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "model = torch.load('lab3/net_attempt2.pth').to(device)\n",
    "\n",
    "img, true_mask = valid_dataset[40]\n",
    "prediction = model(img.unsqueeze(0).to(device)).cpu().detach().squeeze(0)\n",
    "\n",
    "true_mask  = true_mask > .5\n",
    "prediction = prediction > .5\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize= (7, 7))\n",
    "display_img_with_masks(ax1, img, true_mask)\n",
    "display_img_with_masks(ax2, img, prediction)\n",
    "display_masks(ax3, true_mask)\n",
    "display_masks(ax4, prediction)\n",
    "\n",
    "# (\n",
    "#   torch.max(true_mask),\n",
    "#   torch.max(prediction),\n",
    "# )\n",
    "# (\n",
    "#   torch.count_nonzero(true_mask),\n",
    "# ),(\n",
    "#   torch.count_nonzero(true_mask != .0),\n",
    "#   (true_mask != .0).float()[0,0,0]\n",
    "# )\n",
    "# prediction.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# t1 = t(\n",
    "# # batch\n",
    "# [\n",
    "#   # masks for img 1\n",
    "#   [\n",
    "#     # mask for class 1\n",
    "#     [[.2, .1], [.1, .3]],\n",
    "#     # mask for class 2\n",
    "#     [[.2, .1], [.1, .3]],\n",
    "#     # mask for class 3\n",
    "#     [[.2, .1], [.1, .3]],\n",
    "#   ],\n",
    "#   # masks for img 2\n",
    "#   [\n",
    "#     [[.2, .1], [.1, .5]],\n",
    "#     [[.2, .1], [.1, .0]],\n",
    "#     [[.2, .1], [.1, .3]],\n",
    "#   ],\n",
    "#   # masks for img 3\n",
    "#   [\n",
    "#     [[.2, .1], [.1, .0]],\n",
    "#     [[.2, .1], [.1, .0]],\n",
    "#     [[.2, .1], [.1, .3]],\n",
    "#   ]\n",
    "# ])\n",
    "# \n",
    "# \n",
    "# # values, indices = t1.max(t([0, 2]))\n",
    "# # (\n",
    "# #   t1,\n",
    "# #   values,\n",
    "# #   (values ** (-1)) #.repeat(3) #.reshape((2, 3)) * t1\n",
    "# # )\n",
    "# \n",
    "# BATCH_SIZE = t(t1.shape)[0]\n",
    "# CLASS_NO = t(t1.shape)[1]\n",
    "# DIM = t(t1.shape)[2]\n",
    "# \n",
    "# vals, ix = t1.max(dim = -1)[0].max(dim = -1)[0].max(dim = -1)\n",
    "# vals = vals ** -1\n",
    "# t2 = vals.repeat_interleave(CLASS_NO * DIM * DIM).view((BATCH_SIZE, CLASS_NO, DIM, DIM))\n",
    "# (\n",
    "#   # vals.repeat(CLASS_NO).reshape((CLASS_NO, 2)).transpose(dim0 = 0, dim1 = 1)\n",
    "#     # .repeat((2, 3))\n",
    "#   # vals.repeat(t1.shape)\n",
    "#   t(t1.shape),\n",
    "#   (BATCH_SIZE, CLASS_NO, DIM, DIM),\n",
    "#   # vals.repeat(t(t1.shape)[:-1].flipud().tolist()).shape\n",
    "#   vals,\n",
    "#   BATCH_SIZE * CLASS_NO * DIM * DIM,\n",
    "#   t(t1.shape).prod(),\n",
    "#   t1 * t2,\n",
    "#   # vals.repeat_interleave(BATCH_SIZE * CLASS_NO * DIM * DIM).shape,\n",
    "#     # vals.repeat_interleave(t(t1.shape).tolist()).shape\n",
    "#   # t1 * vals\n",
    "#   # t1 * vals.repeat_interleave(BATCH_SIZE * CLASS_NO * DIM * DIM).view((2, 3, 2, 2, 2)),\n",
    "#   # (t2 / t1)\n",
    "#   # t2 / t1\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
