{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:48:39.011549Z",
     "start_time": "2024-05-06T17:48:38.974214Z"
    }
   },
   "source": [
    "from importlib import reload\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lab3\n",
    "reload(lab3)\n",
    "\n",
    "import lab3.classes\n",
    "reload(lab3.classes)\n",
    "import lab3.classes as cs\n",
    "\n",
    "import lab3.show\n",
    "reload(lab3.show)\n",
    "from lab3.show import display_img_with_masks\n",
    "\n",
    "import lab3.trans\n",
    "reload(lab3.trans)\n",
    "from lab3.trans import validation_trans, train_trans, test_trans\n",
    "\n",
    "import lab3.dataset\n",
    "reload(lab3.dataset)\n",
    "from lab3.dataset import FiftyOneDataset\n",
    "\n",
    "import lab3.net\n",
    "reload(lab3.net)\n",
    "from lab3.net import Net\n",
    "\n",
    "import lab1.device\n",
    "reload(lab1.device)\n",
    "from lab1.device import device\n",
    "\n",
    "import lab3.util\n",
    "reload(lab3.util)\n",
    "from lab3.util import seconds_to_time\n",
    "\n",
    "device"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domantelio/Projects/gmm/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:48:50.185878Z",
     "start_time": "2024-05-06T17:48:39.013148Z"
    }
   },
   "source": [
    "from typing import Literal\n",
    "import fiftyone as fo\n",
    "import fiftyone.utils.openimages as fouo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "def download(split = \"train\", max_samples: int = 2000):\n",
    "  return foz.load_zoo_dataset(\n",
    "    \"open-images-v6\",\n",
    "    split        = split,\n",
    "    label_types  = [\"segmentations\", \"detections\"],\n",
    "    classes      = cs.classes_no_background,\n",
    "    max_samples  = max_samples,\n",
    "    dataset_dir  = \"data-lab3\",\n",
    "    dataset_name =f\"open-images-v6-{split}\"\n",
    "  )\n",
    "\n",
    "def load(split = \"train\"):\n",
    "  dataset =  fouo.OpenImagesV6DatasetImporter(\n",
    "    dataset_dir = f\"data-lab3/{split}\",\n",
    "    label_types = \"segmentations\"\n",
    "  )\n",
    "\n",
    "  dataset.setup()\n",
    "\n",
    "  return dataset\n",
    "\n",
    "# train_ds = download(\"train\")\n",
    "# valid_ds = download(\"validation\", max_samples = 300)\n",
    "# test_ds  = download(\"test\", max_samples = 300)\n",
    "\n",
    "train_ds = load(\"train\")\n",
    "valid_ds = load(\"validation\")\n",
    "\n",
    "train_ds #, fo.list_datasets()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fiftyone.utils.openimages.OpenImagesV6DatasetImporter at 0x33e93bd40>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:49:49.075234Z",
     "start_time": "2024-05-06T17:48:50.187075Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "train_dataset = FiftyOneDataset(train_ds, train_trans)\n",
    "valid_dataset = FiftyOneDataset(valid_ds, validation_trans)\n",
    "\n",
    "num_workers = 8\n",
    "batch_size = 128\n",
    "\n",
    "train_ld = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = True)\n",
    "valid_ld = torch.utils.data.DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = False)\n",
    "\n",
    "print(f'Train: {len(train_dataset)}, Test: {len(valid_dataset)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 808, Test: 157\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:49:49.085981Z",
     "start_time": "2024-05-06T17:49:49.076518Z"
    }
   },
   "source": [
    "ZERO = torch.zeros(0, 6, 128, 128) < 1\n",
    "\n",
    "class Stats:\n",
    "  loss_acum = t([])\n",
    "  y_hats = ZERO.clone()\n",
    "  ys = ZERO.clone()\n",
    "  \n",
    "  def init(self):\n",
    "    pass\n",
    "  \n",
    "  def add_data(self, ys = ZERO.clone(), y_hats = ZERO.clone(), loss = t([])):\n",
    "    self.y_hats = c((self.y_hats, ys), dim = 0)\n",
    "    self.ys = c((self.ys, y_hats), dim = 0)\n",
    "    self.loss_acum = c((self.loss_acum, loss))\n",
    "  \n",
    "  def get_stats(self):\n",
    "    ys = self.ys\n",
    "    y_hats = self.y_hats\n",
    "\n",
    "    intersection = torch.bitwise_and(ys, y_hats)\n",
    "    union = torch.bitwise_or(ys, y_hats)\n",
    "\n",
    "    intersection = torch.sum(intersection)\n",
    "    union = torch.sum(union)\n",
    "\n",
    "    # Jaccard = || A \\intersect B || / || A \\union B ||\n",
    "    iou = intersection / union\n",
    "\n",
    "    # DICE = 2 || A \\intersect B || / (||A|| + ||B||)\n",
    "    dice = 2 * intersection / (torch.sum(ys) + torch.sum(y_hats))\n",
    "\n",
    "    # Flatten the tensors\n",
    "    ys_flat = ys.view(-1).numpy()\n",
    "    y_hats_flat = y_hats.view(-1).numpy()\n",
    "\n",
    "    # Calculate Micro-F1 and Macro-F1 scores\n",
    "    micro_f1 = f1_score(ys_flat, y_hats_flat, average='micro')\n",
    "    macro_f1 = f1_score(ys_flat, y_hats_flat, average='macro')\n",
    "\n",
    "    return iou.item(), dice.item(), micro_f1.item(), macro_f1.item(), torch.mean(self.loss_acum)\n",
    "\n",
    "def run_epoch(model: Net,\n",
    "              loader: torch.utils.data.DataLoader,\n",
    "              loss_fn, optimizer):\n",
    "  stats = Stats()\n",
    "  IS_TRAIN = optimizer is not None\n",
    "  \n",
    "  if IS_TRAIN:\n",
    "    model.train()\n",
    "  else:\n",
    "    model.eval()\n",
    "\n",
    "  ix = -1\n",
    "  for images, true_masks in loader:\n",
    "    images = images.to(device)\n",
    "    true_masks = true_masks.to(device)\n",
    "    \n",
    "    if not IS_TRAIN:\n",
    "      with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "    else:\n",
    "      predictions = model(images)\n",
    "\n",
    "    loss = loss_fn(true_masks, predictions)\n",
    "\n",
    "    true_masks = true_masks > 0.5\n",
    "    predictions = predictions > 0.5\n",
    "    \n",
    "    stats.add_data(true_masks.cpu().detach(), predictions.cpu().detach(), loss.cpu().detach())\n",
    "    \n",
    "    if IS_TRAIN:\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "    if ix == 0:\n",
    "      break\n",
    "    ix -= 1\n",
    "\n",
    "  return stats.get_stats()\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:49:49.091720Z",
     "start_time": "2024-05-06T17:49:49.086645Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_and_eval(model, train_ld, valid_ld, epoch_count = 10, learning_rate = 1e-3):\n",
    "  loss_func = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "  start_time = datetime.now()\n",
    "\n",
    "  train_loss_acum = []\n",
    "  train_iou_acum  = []\n",
    "  train_dice_acum = []\n",
    "  train_micro_acum = []\n",
    "  train_macro_acum = []\n",
    "  valid_loss_acum = []\n",
    "  valid_iou_acum  = []\n",
    "  valid_dice_acum = []\n",
    "  valid_micro_acum = []\n",
    "  valid_macro_acum = []\n",
    "  \n",
    "  for epoch in range(epoch_count):\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    train_iou, train_dice, train_micro, train_macro, train_loss = run_epoch(model, train_ld, loss_func, optimizer)\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    elapsed = seconds_to_time((current_time - start_time).total_seconds())\n",
    "    print(f'  train      | Elapsed: {elapsed}')\n",
    "\n",
    "    valid_iou, valid_dice, valid_micro, valid_macro, valid_loss = run_epoch(model, valid_ld, loss_func, optimizer)\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    elapsed = seconds_to_time((current_time - start_time).total_seconds())\n",
    "    print(f'  valid      | Elapsed: {elapsed}')\n",
    "\n",
    "    train_iou_acum.append(train_iou)\n",
    "    train_dice_acum.append(train_dice)\n",
    "    train_micro_acum.append(train_micro)\n",
    "    train_macro_acum.append(train_macro)\n",
    "    train_loss_acum.append(train_loss)\n",
    "    \n",
    "    valid_iou_acum.append(valid_iou)\n",
    "    valid_dice_acum.append(valid_dice)\n",
    "    valid_micro_acum.append(valid_micro)\n",
    "    valid_macro_acum.append(valid_macro)\n",
    "    valid_loss_acum.append(valid_loss)\n",
    "\n",
    "    print(f'  Training Loss:  {train_loss},  Validation Loss:  {valid_loss}')\n",
    "    print(f'  Training IoU:   {train_iou},   Validation IoU:   {valid_iou}')\n",
    "    print(f'  Training Dice:  {train_dice},  Validation Dice:  {valid_dice}')\n",
    "    print(f'  Training Micro: {train_micro}, Validation Micro: {valid_micro}')\n",
    "    print(f'  Training Macro: {train_macro}, Validation Macro: {valid_macro}')\n",
    "\n",
    "  return train_iou_acum, valid_iou_acum, train_dice_acum, valid_dice_acum, train_micro_acum, valid_micro_acum, train_macro_acum, valid_macro_acum, train_loss_acum, valid_loss_acum"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:49:49.094779Z",
     "start_time": "2024-05-06T17:49:49.092672Z"
    }
   },
   "source": [
    "def plot(train, valid, label = \"IoU\"):\n",
    "  plt.clf()\n",
    "  plt.plot(train, 'b', label = f'Training {label}')\n",
    "  plt.plot(valid, 'r', label = f'Validation {label}')\n",
    "  plt.ylim(0.0, 1.0)\n",
    "  plt.legend()\n",
    "  plt.show()"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:50:20.822422Z",
     "start_time": "2024-05-06T17:49:49.095419Z"
    }
   },
   "source": [
    "model = Net(train_dataset[0][0].shape[0], num_classes = cs.num_classes).to(device)\n",
    "print(f'Parameter count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "train_iou, valid_iou, train_dice, valid_dice, train_micro, valid_micro, train_macro, valid_macro, train_loss, valid_loss = train_and_eval(model, train_ld, valid_ld, epoch_count = EPOCHS, learning_rate = 1e-3)\n",
    "plot(train_iou, valid_iou)\n",
    "plot(train_dice, valid_dice, label = \"dice\")\n",
    "plot(train_micro, valid_micro, label = \"micro\")\n",
    "plot(train_macro, valid_macro, label = \"macro\")\n",
    "plot(train_loss, valid_loss, label = \"loss\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count: 1,928,582\n",
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(2229) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(2230) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(2231) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(2233) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(2234) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(2235) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(2238) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(2239) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 17.85 GB, other allocations: 258.83 MB, max allowed: 18.13 GB). Tried to allocate 256.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mParameter count: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(p\u001B[38;5;241m.\u001B[39mnumel()\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mp\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mmodel\u001B[38;5;241m.\u001B[39mparameters()\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mp\u001B[38;5;241m.\u001B[39mrequires_grad)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m EPOCHS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m30\u001B[39m\n\u001B[0;32m----> 6\u001B[0m train_iou, valid_iou, train_dice, valid_dice, train_micro, valid_micro, train_macro, valid_macro, train_loss, valid_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_ld\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_ld\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch_count\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1e-3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m plot(train_iou, valid_iou)\n\u001B[1;32m      8\u001B[0m plot(train_dice, valid_dice, label \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdice\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[27], line 22\u001B[0m, in \u001B[0;36mtrain_and_eval\u001B[0;34m(model, train_ld, valid_ld, epoch_count, learning_rate)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epoch_count):\n\u001B[1;32m     21\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEPOCH: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 22\u001B[0m   train_iou, train_dice, train_micro, train_macro, train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mrun_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_ld\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m   current_time \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow()\n\u001B[1;32m     25\u001B[0m   elapsed \u001B[38;5;241m=\u001B[39m seconds_to_time((current_time \u001B[38;5;241m-\u001B[39m start_time)\u001B[38;5;241m.\u001B[39mtotal_seconds())\n",
      "Cell \u001B[0;32mIn[26], line 62\u001B[0m, in \u001B[0;36mrun_epoch\u001B[0;34m(model, loader, loss_fn, optimizer)\u001B[0m\n\u001B[1;32m     60\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m model(images)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 62\u001B[0m   predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(true_masks, predictions)\n\u001B[1;32m     66\u001B[0m true_masks \u001B[38;5;241m=\u001B[39m true_masks \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/gmm/lab3/net.py:52\u001B[0m, in \u001B[0;36mNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     51\u001B[0m   \u001B[38;5;66;03m# Contracting Path\u001B[39;00m\n\u001B[0;32m---> 52\u001B[0m   c1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m   p1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool1(c1)\n\u001B[1;32m     54\u001B[0m   d1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop1(p1)\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/gmm/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 17.85 GB, other allocations: 258.83 MB, max allowed: 18.13 GB). Tried to allocate 256.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:50:20.823289Z",
     "start_time": "2024-05-06T17:50:20.823234Z"
    }
   },
   "source": [
    "torch.save(model, 'lab3/net_attempt2.pth')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T17:50:20.824159Z",
     "start_time": "2024-05-06T17:50:20.823912Z"
    }
   },
   "source": [
    "model = torch.load('lab3/net_attempt2.pth').to(device)\n",
    "\n",
    "img, true_mask = valid_dataset[40]\n",
    "y = true_mask\n",
    "mask = model(img.unsqueeze(0).to(device)).cpu().detach().squeeze(0)\n",
    "# mask = mask < .9\n",
    "\n",
    "# aggregated_mask = lab3.dataset.aggregate_detections(mask)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize= (8, 3))\n",
    "display_img_with_masks(ax1, img, true_mask)\n",
    "display_img_with_masks(ax2, img, mask)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
